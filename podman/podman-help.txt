

-----------------------------------------------------------------------

podman
podman-compose
podman-docker
podman-dnsname
buildah
cockpit
cockpit-podman



Example.

[user@rhel8~]$ podman search ssh

[user@rhel8~]$ grep registries /etc/containers/registries.conf

[user@rhel8~]$ podman search registry

[user@rhel8~]$ podman pull docker.io/library/regisrty

[user@rhel8~]$ podman images

[user@rhel8~]$ mkdir registry

[user@rhel8~]$ podman run --name myregistry -p 5000:5000 -v /home/mikl/registry:/var/lib/registry:Z -d registry

[user@rhel8~]$ podman ps

[user@rhel8~]$ podman logs myregistry

[user@rhel8~]$ podman -it myregistry sh

[user@rhel8~]$ podman -exec -d myregistry touch /var/lib/registry/file
[user@rhel8~]$ ls registry/
[user@rhel8~]$ rm -rf registry/file

[user@rhel8~]$ podman images

[user@rhel8~]$ podman tag docker.io/library/regisrty:latest rhel8:5000/registry

[user@rhel8~]$ podman images

[user@rhel8~]$ podman push rhel8:5000/registry

...Error...HTTPS...

[user@rhel8~]$ sudo nano /etc/containers/registries.conf

[[registry]]
location = "rhel8:5000"
insecure=true

[user@rhel8~]$ podman push rhel8:5000/registry

OK

[user@rhel8~]$ ls registry/docker/registry/v2/

[user@rhel8~]$ podman images

[user@rhel8~]$ podman images rm docker.io/library/regisrty

Untagged:...

[user@rhel8~]$ podman search httpd | head 3

...
fedoraproject.org registry.fedoraproject.org/f29/httpd ...

[user@rhel8~]$ skopeo copy docker://registry.fedoraproject.org/f29/httpd docker://rhel8:5000/httpd

[user@rhel8~]$ podman search rhel8:5000/httpd

[user@rhel8~]$ podman pull rhel8:5000/httpd

[user@rhel8~]$ podman images



[user@rhel8~]$ podman generate systemd --restart-policy=always -t 1 --files --name myregistry

/home/user/container-myregistry.service

[user@rhel8~]$ mkdir -p ~/.config/systemd/user/

[user@rhel8~]$ cp container-myregistry.service ~/.config/systemd/user/

[user@rhel8~]$ systemctl --user enable container-myregistry.service

[user@rhel8~]$ loginctl enable-linger user

[user@rhel8~]$ sudo reboot

mikl@mikl -> ssh root@rhel

[user@rhel8~]$  nc -zv localhost 5000
...
Ncat: Connected to ::1:5000
...
[user@rhel8~]$ podman ps
...
[user@rhel8~]$ su - user

[user@rhel8~]$ podman ps



IF NEED 80 PORT.

[user@rhel8~]$ sudo firewall-cmd --add-forward-port=port=80:proto=tcp:toport=5000 --permanent

[user@rhel8~]$ sudo firewall-cmd --reload


cockpit: https:ip:9090/podman





The Digital Life.

root: useradd xcad -m -s /bin/bash -c "admin user"
root: usermod -aG sudo xcad
root: passwd xcad
root: mkdir -p /home/xcad/.ssh/

paste the ssh public.key to /home/xcad/.ssh/autorized_keys 

root: chown xcad:xcad /home/xcad/.ssh/authorized_keys
root: exit

ssh xcad@ip


sudo apt install podman cockpit cockpit-podman -y
sudo systemctl status cockpit

Browser
https://ip:9090
The SSL certificate to self signed is CORRECT.

$ pip3 install podman-compose
$ nano ~/.bashrc
export PATH=$PATH:/$HOME/.local/bin/

$ cd opt
$ sudo mkdir npm
$ sudo chown xcad:xcad npm

$ nano docker-compose.yml

version: '3'
services:
  app:
    image: 'docker.io/jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    environment:
      DB_MYSQL_HOST: "db"
      DB_MYSQL_PORT: 3306
      DB_MYSQL_USER: "npm"
      DB_MYSQL_PASSWORD: "npm"
      DB_MYSQL_NAME: "npm"
    volumes:
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt
  db:
    image: 'docker.io/jc21/mariadb-aria:latest'
    environment:
      MYSQL_ROOT_PASSWORD: 'npm'
      MYSQL_DATABASE: 'npm'
      MYSQL_USER: 'npm'
      MYSQL_PASSWORD: 'npm'
    volumes:
      - ./data/mysql:/var/lib/mysql
    restart: unless-stopped



mkdir -p data/mysql letsecrypt

podman-compose up -d

Error to PORT 80 and 443.

nano /etc/sysctl.conf

net.ipv4.ip_unprivileged_port_start=80

sudo sysctl -p

podman-compose up -d

podman ps --all

SSL to cockpit.
Nginx Proxy Manager - generate SSL certificate and Proxy Host to domain.

$ ip a
1. lo: ...
...
2: eht0
inet 104.248.38.139/20 brd 104.248.47.255 scrope global eth0
inet 10.19.0.8/16 brd 10.19.255.255 scope global eth0
...


Nginx Proxy Manager - Proxy Host.
Details:
my.example.com
https 10.19.0.8 9090
Block Common Exploits
Websockets Support

SSL:
Force SSL
HTTP/2 Support
HSTS Enabled

Domain active and STOP 10.19.0.8 public ip address = access denied.

sudo mkdir -p /etc/systemd/system/cockpit.socket.d
sudo nano /etc/systemd/system/cockpit.socket.d/listen.conf

[Socket]
ListenStream=
ListenStream=10.19.0.8:9090
FreeBind=yes

sudo systemctl daemon-reload
sudo systemctl restart cockpit









podman login docker.io




ln -sf /var/run/podman/podman.sock /var/run/docker.sock
sudo systemctl enable --now podman.socket
systemctl --user enable --now podman.socket

podman run -d -p 9000:9000 --privileged --name=portainer --restart=always -v /run/user/$(id -u)/podman/podman.sock:/var/run/docker.sock:Z -v portainer_data:/data docker.io/portainer/portainer-ce


podman pod list

$ podman ps -a
CONTAINER ID  IMAGE                      COMMAND               CREATED         STATUS             PORTS                   NAMES
3636bbe05344  localhost/ol8_ords:latest  /bin/sh -c exec $...  17 minutes ago  Up 17 minutes ago  0.0.0.0:1521->1521/tcp  ol8_ords_con
3dfe524b96dc  localhost/ol8_19:latest    /bin/sh -c exec $...  17 minutes ago  Up 17 minutes ago  0.0.0.0:1521->1521/tcp  ol8_19_con
74a62f158f25  k8s.gcr.io/pause:3.1                             17 minutes ago  Up 17 minutes ago  0.0.0.0:1521->1521/tcp  9a42ad992aa6-infra
$

$ podman generate kube my_pod -f /tmp/my_pod_kube.yaml

Play a Kubernetes YAML File

podman rm -vf ol8_ords_con
podman rm -vf ol8_19_con
podman pod rm my_pod

$ podman ps -a
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS  PORTS  NAMES
$

$ podman play kube /tmp/my_pod_kube_compact.yaml
Pod:
ca53a71fecd8aa19a868739695624b4682fc3818e4889dff331284ec824afd15
Containers:
e8b5f9da27a9ee8b9c77cc0c799cf2e197bbb44df5b5aecc78b09ffabd52dcc0
b1944c9bf62e9947b073ecc9ac2420741a05bdb191c4b4f39c3f843b8e54a519
$

$ podman pod list
POD ID         NAME     STATUS    CREATED          # OF CONTAINERS   INFRA ID
ca53a71fecd8   my_pod   Running   24 seconds ago   3                 9df5f3af12f1
$

$ podman ps -a
CONTAINER ID  IMAGE                      COMMAND               CREATED         STATUS             PORTS                   NAMES
b1944c9bf62e  localhost/ol8_ords:latest  /bin/sh -c exec $...  41 seconds ago  Up 40 seconds ago  0.0.0.0:1521->1521/tcp  ol8_ords_con
e8b5f9da27a9  localhost/ol8_19:latest    /bin/sh -c exec $...  41 seconds ago  Up 40 seconds ago  0.0.0.0:1521->1521/tcp  ol8_19_con
9df5f3af12f1  k8s.gcr.io/pause:3.1                             41 seconds ago  Up 41 seconds ago  0.0.0.0:1521->1521/tcp  ca53a71fecd8-infra
$



podman generate kube webserver

podman generate kube webserver >> webserver.yaml







podman build -t scriptcamp/nginx .

podman push scriptcamp/nginx




$ podman pod create --name pod_names
$ podman ps -a --pod
$ podman run -dt --pod web alpine:latest top
# podman run -dt --pod new:web alpine:latest top

$ sudo podman pod create -p 8080:80 --name web1
$ sudo podman run -dt --pod web1 -p 8080 nginx:latest



Сетевые стеки Pod действуют как сетевой стек на хосте - 
у вас есть множество контейнеров в модуле и программы в контейнере, 
и все они используют один интерфейс, IP-адрес и связанные порты. 
Если один контейнер привязывается к порту, никакой другой контейнер не может использовать этот порт в модуле, 
пока он используется. Контейнеры в модуле также могут взаимодействовать через localhost, 
если один контейнер привязан к localhost в модуле, а другой - к этому порту.

podman pod create --name srcview -p 127.0.0.1:3434:3434 -p 127.0.0.1:7080:7080 -p 127.0.0.1:3370:3370
podman run --pod srcview --name src-expose -v "${PWD}:/var/opt/localrepo":Z,ro sourcegraph/src-expose:latest serve /var/opt/localrepo







Minimal podman communication.

# Entrypoint.
# --entrypoint=”command” | ‘[“command”, “arg1”, …]’
$ podman run -d ... --entrypoint ...

# Expose
$ podman run -d --expose=port ...
# Expose a port, or a range of ports (e.g. --expose=3300-3310) to set up port redirection on the host system.

# --ip=ipv4 # --ip6=ipv6
# -network=network-name
# Specify a static IPv4 address for the container, for example 10.88.64.128. 
# This option can only be used if the container is joined to only a single network - i.e., 
# --network=network-name is used at most once - 
# and if the container is not joining another container’s network namespace via --network=container:id. 
# The address must be within the network’s IP address pool (default 10.88.0.0/16).

--network=mode, --net
# Set the network mode for the container. 
# Invalid if using --dns, --dns-opt, or --dns-search with --network set to none or container:id. 
# If used together with --pod, the container will not join the pod’s network namespace.
# bridge[:OPTIONS,…]:
# alias=name
# ip=IPv4
# ip=IPv6
# mac=MAC
# interface_name
#
# none # container:id # host # ns:path # private # 
--network bridge:ip=10.88.0.10,mac=44:33:22:11:00:99

--network-alias=alias

--restart-policy=policy
# Set the systemd restart policy. 
# The restart-policy must be one of: “no”, “on-success”, “on-failure”, “on-abnormal”, “on-watchdog”, “on-abort”, or “always”. 
# The default policy is on-failure.

--dns=ipaddr

--dns-search=domain

# Simple.
$ podman run -d -p 8585:8888 --name=web-name --restart=always -e env=env -v ./volume:/volume docker.io/images

# Hard.
$ podman pod create --name pod_names
or
$ podman run -dt --pod new:web alpine:latest top

# Sudo. 
# sudo podman pod create -p 8080:80 --name web1
or
# sudo podman run -dt --pod new:web1 -p 8080 nginx:latest

$ podman pod ls
# sudo podman pod ls
$ podman generate kube pod_name -f ./searx.yaml

$ nano podman.yaml

$ podman generate systemd --restart-policy=always -t 1 --files --name pod_name


Создание модуля, не использующего сетевое пространство имен, 
и поэтому отображение портов будет основано на контейнерах, а не на модулях.

$ podman pod create --name servers --share cgroup,ipc,uts
$ podman run -dt --pod servers --rm --name web -p 80:80 $WEB_PATH php:7.2-apache
$ podman run -dt --pod servers --rm --name mysql --env MYSQL_ROOT_PASSWORD=iamroot -v /var/lib/mysql:/var/lib/mysql:Z -p 8080:8080 mysql:8
$ podman run -dt --pod servers --rm --name pma -p SOMEPORT:80 phpmyadmin/phpmyadmin:5










MYSQL AS NON-ROOT.

$ podman run --rm -v $HOME/mysql-data:/var/lib/mysql/data:Z -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -p 3306:3306 mariadb/server
Permission denied …

$ podman run -ti mariadb/server grep mysql /etc/passwd
mysql:x:999:999::/home/mysql:/bin/sh

$ chown 999:999 -R $HOME/mysql-data
Permission denied …

But the user is going to get permission denied. Furthermore, this is the wrong UID:GID pair. 
Remember that the UID:GID pair is relative to the user namespace that the user is going to run the container with. 
Now we have a big math problem. 
We must look at the user namespace the user going to run the container with and then add 999 to the beginning UID of the range - 1. 
And hope we got it right.
Но пользователю будет отказано в разрешении. Кроме того, это неправильная пара UID:GID. 
Помните, что пара UID:GID относится к пользовательскому пространству имен, с которым пользователь собирается запустить контейнер. 
Теперь у нас есть большая математическая проблема. 
Мы должны посмотреть на пространство имен пользователя, с которым пользователь собирается запустить контейнер, а затем добавить 999 в начальную строку диапазона - 1. 
И надеюсь, что мы все сделали правильно.

$ sudo chown CONTAINER999:CONTAINER999 -R $HOME/mysql-data

An easier way to handle this situation would be to use podman unshare. 
The unshare command is a cool command that joins the user namespace without running any containers.
For example, the user could enter.
Более простым способом справиться с этой ситуацией было бы использовать pod man unshare. 
Команда unshare - это классная команда, которая присоединяется к пользовательскому пространству имен без запуска каких-либо контейнеров.
Например, пользователь может ввести.

$ podman unshare chown 999:999 -R $HOME/mysql-data

Now the user is ready to run the rootless container with the following command.
Теперь пользователь готов запустить контейнер без корня со следующей командой.

$ podman run --rm -v $HOME/mysql-data:/var/lib/mysql/data:Z -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -p 3306:3306 mariadb/server



PODMAN COMMAND "UNSHARE" - DESCRIPTION.

Launches a process (by default, $SHELL) in a new user namespace. 
The user namespace is configured so that the invoking user’s UID and primary GID appear to be UID 0 and GID 0, respectively. 
Any ranges which match that user and group in /etc/subuid and /etc/subgid 
are also mapped in as themselves with the help of the newuidmap(1) and newgidmap(1) helpers.
Запускает процесс (по умолчанию, $SHELL) в новом пользовательском пространстве имен. 
Пространство имен пользователя настроено таким образом, чтобы UID вызывающего пользователя и основной GID отображались как UID 0 и GID 0 соответственно. 
Любые диапазоны, которые соответствуют этому пользователю и группе в /etc/subuid и /etc/subgid, 
также отображаются как сами по себе с помощью помощников newuidmap(1) и newgidmap(1).






Kubernetes.

pods/commands.yaml

apiVersion: v1
kind: Pod
metadata:
  name: command-demo
  labels:
    purpose: demonstrate-command
spec:
  containers:
  - name: command-demo-container
    image: debian
    command: ["printenv"]
    args: ["HOSTNAME", "KUBERNETES_PORT"]
  restartPolicy: OnFailure



Use environment variables to define arguments.

env:
- name: MESSAGE
  value: "hello world"
command: ["/bin/echo"]
args: ["$(MESSAGE)"]


Run a command in a shell.

command: ["/bin/sh"]
args: ["-c", "while true; do echo hello; sleep 10;done"]





















